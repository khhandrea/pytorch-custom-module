network_spec:
  cnn:
    initialization: True
    layers:
      # 3 x 64 x 64
      - layer: conv2d 
        spec: [3, 32, 3, 2, 1]
        activation: elu
        # 32 x 32 x 32
      - layer: conv2d
        spec: [32, 32, 3, 2, 1]
        activation: elu
        # 32 x 16 x 16
      - layer: conv2d
        spec: [32, 32, 3, 2, 1]
        activation: elu
        # 32 x 8 x 8 
      - layer: conv2d
        spec: [32, 32, 3, 2, 1]
        activation: elu
        # 32 x 4 x 4 (= 256)
      - layer: flatten

  linear:
    initialization: false
    layers:
      - layer: linear
        spec: [512, 256]
        activation: relu
      - layer: linear
        spec: [256, 5]
        activation: softmax

  lstm:
    initialization: True
    layers:
      - layer: lstm
        spec: [260, 256, 1]
        activation: relu